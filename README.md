# ğŸ“§ Spam Detection using NaÃ¯ve Bayes

## ğŸ“ Project Description

This project implements a Spam Detection System using NaÃ¯ve Bayes Classification.

The goal is to classify text messages (emails or SMS) as spam or not spam based on word frequency features such as "free", "money", "offer".

The model is trained and evaluated on a synthetic dataset to demonstrate the process of building a spam filter.

## ğŸ“‚ Dataset

Dataset used: synthetic_spam_dataset_extended.csv

Features include:

ğŸ“Œ word_freq_free â†’ frequency of word "free"

ğŸ“Œ word_freq_money â†’ frequency of word "money"

ğŸ“Œ word_freq_offer â†’ frequency of word "offer"

ğŸ“Œ char_freq_$ â†’ frequency of symbol "$"

Target column: label â†’ (1 = Spam, 0 = Not Spam)

## âš™ï¸ Requirements

Install the following Python libraries:

ğŸ¼ pandas

ğŸ“Š matplotlib

ğŸ¨ seaborn

ğŸ¤– scikit-learn

ğŸ’¾ pickle (for saving/loading models)

## ğŸš€ How to Run

ğŸ“¥ Clone the repository or download the files.

ğŸ“‚ Place the dataset (synthetic_spam_dataset_extended.csv) in the same directory.

ğŸ–¥ï¸ Open and run the Jupyter Notebook:

jupyter notebook spam.ipynb


The notebook performs:

ğŸ” Data exploration (EDA)

ğŸ§¹ Preprocessing (check nulls, duplicates)

âœ‚ï¸ Train-test split

ğŸ§  Training with Gaussian NaÃ¯ve Bayes

ğŸ“ˆ Model evaluation (accuracy, confusion matrix, classification report, ROC curve)

ğŸ’¾ Saving the model using pickle

## ğŸ“Š Results

âœ… The Gaussian NaÃ¯ve Bayes classifier achieved high accuracy on the dataset.

ğŸ“‘ Evaluation metrics used:

ğŸ¯ Accuracy Score

ğŸ“Š Precision, Recall, F1-score (Classification Report)

ğŸ—‚ï¸ Confusion Matrix

ğŸ“‰ ROC Curve & AUC Score

<img width="691" height="545" alt="image" src="https://github.com/user-attachments/assets/edca7a5e-031e-4be2-b4a9-511a147d4ee7" />


## âœ… Conclusion

âœ¨ The NaÃ¯ve Bayes classifier is a simple yet effective method for spam detection.

ğŸ“© Using word frequency features, the model successfully distinguishes between spam and non-spam.

ğŸ“ˆ Gaussian NaÃ¯ve Bayes was chosen because the features are continuous word frequencies, not binary or raw counts.

## ğŸ”® Future Development

ğŸŒ Use real-world datasets (SMS Spam Collection, Enron Email).

ğŸ”„ Try other NaÃ¯ve Bayes variants: MultinomialNB, BernoulliNB.

ğŸ§© Feature engineering: message length, links, suspicious domains.

ğŸ¤ Compare with Logistic Regression, Random Forest, Gradient Boosting, Deep Learning (LSTMs, BERT).

ğŸŒ Deploy as a web app using Flask or Streamlit.

## ğŸ“ Files

ğŸ““ spam.ipynb â†’ Main Jupyter Notebook

ğŸ“„ synthetic_spam_dataset_extended.csv â†’ Dataset

ğŸ’¾ spam_model.pkl â†’ Saved model
